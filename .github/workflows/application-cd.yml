name: theBarcodeApi Application Deployment

# on:
#   workflow_run:
#     workflows: ["theBarcodeApi Infrastructure Setup"]
#     branches: [main]
#     types:
#       - completed
on:
  push:
    branches:
      - main
    tags:
      - 'v*.*.*' # For tags like v0.1.0
      - '*.*.*'  # For tags like 0.1.0 (without v prefix)
      - '*'      # Fallback for any other tag format if needed, be cautious with too broad patterns
  workflow_dispatch:
    inputs:
      branch:
        description: 'Branch or Tag to deploy'
        required: false
        default: 'main'

env:
  # Domain name for the application, used by web server configurations (e.g., in Nginx)
  DOMAIN_NAME: ${{ secrets.DOMAIN_NAME }}
  # Deployment environment (e.g., staging, production)
  ENVIRONMENT: ${{ vars.ENVIRONMENT }}
  # Sudo password for privileged operations on the self-hosted runner
  SUDO_PASSWORD: ${{ secrets.SUDO_PASSWORD }}
  # Database password for the main application user (e.g., barcodeboachiefamily)
  DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
  # PostgreSQL superuser (postgres user) password
  POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
  # Secret key used for JWT token generation and other security functions in the API
  API_SECRET_KEY: ${{ secrets.API_SECRET_KEY }}
  # Master API key for administrative or high-privilege API access
  API_MASTER_KEY: ${{ secrets.API_MASTER_KEY }}
  # Version of the API, used for documentation, releases, and potentially in build arguments
  API_VERSION: ${{ vars.API_VERSION }}

jobs:
  frontend-deployment:
    runs-on: self-hosted
    # This job runs if the event is a push or a manual workflow dispatch.
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    steps:
    # Determines the branch to checkout.
    # For manual 'workflow_dispatch', it uses the 'branch' input or the current ref_name if input is not provided.
    # For other events (like a push, though the trigger is currently commented out), it defaults to github.ref_name.
    - name: Determine branch to deploy
      id: get_branch
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "branch=${{ github.event.inputs.branch || github.ref_name }}" >> $GITHUB_OUTPUT
        else
          echo "branch=${{ github.ref_name }}" >> $GITHUB_OUTPUT
        fi

    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        ref: ${{ steps.get_branch.outputs.branch }}

    # Executes a script to determine if there are changes in the frontend codebase compared to the last deployed commit.
    # Outputs 'changes=true' or 'changes=false' to GITHUB_OUTPUT, which is used by subsequent steps.
    - name: Check for frontend code changes
      id: check_frontend_changes
      run: bash ./scripts/check-frontend-changes.sh
      env:
        ENVIRONMENT: ${{ env.ENVIRONMENT }}
        GITHUB_OUTPUT: ${{ github.outputs.GITHUB_OUTPUT }} # Allows script to set output for other steps

    # Validates that essential environment variables are set if frontend changes are detected and a build/deployment is needed.
    - name: Validate essential environment variables
      if: steps.check_frontend_changes.outputs.changes == 'true'
      run: |
        for var in ENVIRONMENT DB_PASSWORD POSTGRES_PASSWORD API_SECRET_KEY API_MASTER_KEY; do
          if [ -z "${!var}" ]; then
            echo "Error: $var is not set"
            exit 1
          fi
        done

    - name: Use Node.js
      if: steps.check_frontend_changes.outputs.changes == 'true'
      uses: actions/setup-node@v3
      with:
        node-version: '20.x'
        cache: 'npm'

    # Caches Next.js build artifacts (.next/cache) and downloaded dependencies (node_modules)
    # to speed up subsequent builds if frontend changes are detected.
    # The cache key is composed of the runner's OS, a hash of package-lock.json, and hashes of all JS/TS(X) files.
    # A less specific restore key (without source file hashes) is provided as a fallback.
    - name: Cache Next.js build artifacts and dependencies
      if: steps.check_frontend_changes.outputs.changes == 'true'
      uses: actions/cache@v3
      with:
        path: |
          .next/cache
          node_modules
        key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}
        restore-keys: |
          ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-

    # Installs npm dependencies using 'npm ci' for a clean, reproducible install from package-lock.json.
    # Then, it runs linting and the build process for the Next.js application.
    - name: Install dependencies, lint, and build frontend
      if: steps.check_frontend_changes.outputs.changes == 'true'
      run: |
        npm ci
        npm run lint
        npm run build

    # Executes the main frontend deployment script.
    # This script handles tasks like creating a new release directory, updating symlinks,
    # managing the PM2 process for the frontend application, and performing health checks with rollback capabilities.
    - name: Deploy frontend application and perform health check
      run: bash ./scripts/deploy-frontend.sh
      env:
        ENVIRONMENT: ${{ env.ENVIRONMENT }}
        SUDO_PASSWORD: ${{ env.SUDO_PASSWORD }}
        STEPS_CHECK_FRONTEND_CHANGES_OUTPUTS_CHANGES: ${{ steps.check_frontend_changes.outputs.changes }}

  backend-deployment:
    runs-on: self-hosted
    needs: frontend-deployment # Ensures frontend deployment is attempted first.
    steps:
    # Determines the branch to checkout for the backend deployment.
    # For manual 'workflow_dispatch', it uses the workflow's own ref (branch or tag).
    # For other events, it defaults to 'main'.
    - name: Determine branch for backend deployment
      id: get_branch # Note: ID is same as in frontend job, but it's a local ID to this job.
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "branch=${{ github.event.inputs.branch || github.ref }}" >> $GITHUB_OUTPUT
        else # For push events (to main branch or a tag)
          echo "branch=${{ github.ref }}" >> $GITHUB_OUTPUT # Use the pushed ref (branch or tag)
        fi

    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Fetch all history for all branches and tags, enabling diffs against any prior commit.
        ref: ${{ steps.get_branch.outputs.branch }}

    # Executes a script to determine if there are changes in the backend codebase.
    # Outputs 'changes=true' or 'changes=false' to GITHUB_OUTPUT for use in subsequent steps.
    - name: Check for backend code changes
      id: check_backend_changes
      run: bash ./scripts/check-backend-changes.sh
      env:
        ENVIRONMENT: ${{ env.ENVIRONMENT }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}
        GITHUB_OUTPUT: ${{ github.outputs.GITHUB_OUTPUT }} # Allows script to set output

    # If backend changes are detected, this step cleans the target deployment directory
    # and copies the new backend files into it. A backup of the existing deployment is made first.
    - name: Clean and copy backend files to deployment directory
      if: steps.check_backend_changes.outputs.changes == 'true'
      run: |
        # Create backup of current deployment if it exists
        if [ -d "/opt/thebarcodeapi/barcodeAPI" ]; then
          BACKUP_DIR="/opt/thebarcodeapi/${{ vars.ENVIRONMENT }}/backups/$(date +%Y%m%d_%H%M%S)"
          echo "${{ env.SUDO_PASSWORD }}" | sudo -S mkdir -p "${BACKUP_DIR}"
          echo "${{ env.SUDO_PASSWORD }}" | sudo -S cp -r /opt/thebarcodeapi/barcodeAPI "${BACKUP_DIR}/"
        fi

        # Clean the deployment directory
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -rf /opt/thebarcodeapi/barcodeAPI/*

        # Copy new files
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S cp -r ./barcodeAPI/* /opt/thebarcodeapi/barcodeAPI/

        # Set proper permissions
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S chown -R github-runner:github-runner /opt/thebarcodeapi/barcodeAPI
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S chmod -R 755 /opt/thebarcodeapi/barcodeAPI

        # Debug output
        echo "Contents of deployment directory:"
        ls -la /opt/thebarcodeapi/barcodeAPI/

    # Executes a script to create the .env file required by the backend application.
    # This file contains sensitive information and configuration details.
    - name: Create .env file for backend services
      run: bash ./scripts/create-backend-env-file.sh
      env:
        SUDO_PASSWORD: ${{ env.SUDO_PASSWORD }}
        API_VERSION: ${{ vars.API_VERSION }}
        DB_PASSWORD: ${{ env.DB_PASSWORD }}
        POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
        API_SECRET_KEY: ${{ env.API_SECRET_KEY }}
        API_MASTER_KEY: ${{ env.API_MASTER_KEY }}
        ENVIRONMENT: ${{ env.ENVIRONMENT }}
        DOMAIN_NAME: ${{ env.DOMAIN_NAME }}

    - name: Set up Docker Buildx
      if: steps.check_backend_changes.outputs.changes == 'true'
      uses: docker/setup-buildx-action@v3
      with:
        install: true

    # Sets up Docker Buildx cache using GitHub Actions cache.
    # The cache is keyed by OS, current commit SHA, and hashes of key backend definition files (requirements.txt, Dockerfile, Python/Alembic code).
    # This helps speed up Docker image builds by reusing layers from previous builds.
    - name: Setup Docker Buildx cache layers
      if: steps.check_backend_changes.outputs.changes == 'true'
      uses: actions/cache@v3
      with:
        path: |
          /opt/thebarcodeapi/barcodeAPI/.buildx-cache
          ~/.docker/buildx
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-${{ hashFiles('**/requirements.txt', '**/Dockerfile', 'api/**/*.py', 'alembic/**/*.py') }}
          ${{ runner.os }}-buildx-${{ github.ref_name }}-

    # Builds the Docker image for the backend API.
    # It uses docker/build-push-action, configured to build locally and load the image into the Docker daemon.
    # Caching (cache-from, cache-to) is utilized to optimize build times.
    # `tags` and `labels` would ideally be dynamic e.g. using `docker/metadata-action` if a `meta` step was defined.
    - name: Build and cache Docker image for backend API
      if: steps.check_backend_changes.outputs.changes == 'true'
      uses: docker/build-push-action@v5
      with:
        context: /opt/thebarcodeapi/barcodeAPI # Sets the Docker build context to the backend API code directory.
        file: /opt/thebarcodeapi/barcodeAPI/Dockerfile # Specifies the Dockerfile to be used.
        push: false # The image is not pushed to a container registry.
        load: true  # The built image is loaded into the local Docker daemon on the runner.
        tags: barcodeapi:latest # ${{ steps.meta.outputs.tags }} # Example: barcodeapi:latest or dynamic tags from a meta step.
        labels: ${{ steps.meta.outputs.labels }} # Example: org.opencontainers.image.source=${{ github.repositoryUrl }}
        cache-from: | # Defines sources for build cache.
          type=local,src=/opt/thebarcodeapi/barcodeAPI/.buildx-cache
          type=gha,scope=${{ github.workflow }}-${{ github.ref_name }} # GitHub Actions cache scoped to workflow and branch.
        cache-to: type=local,dest=/opt/thebarcodeapi/barcodeAPI/.buildx-cache-new,mode=min # Exports new cache layers locally.
        build-args: | # Arguments passed to the Docker build.
          DEBIAN_FRONTEND=noninteractive
          PYTHON_ENV=${{ env.ENVIRONMENT }}
          PROJECT_VERSION=${{ env.API_VERSION }}
        platforms: linux/amd64 # Specifies the target platform for the build.
        outputs: type=docker # Defines the output type of the build.
        provenance: false # Disables build provenance attestations.
        sbom: false # Disables SBOM attestations.

    # Moves the newly created Docker Buildx cache to the location expected by subsequent workflow runs for cache restoration.
    - name: Update local Docker build cache
      if: steps.check_backend_changes.outputs.changes == 'true'
      run: |
        rm -rf /opt/thebarcodeapi/barcodeAPI/.buildx-cache
        mv /opt/thebarcodeapi/barcodeAPI/.buildx-cache-new /opt/thebarcodeapi/barcodeAPI/.buildx-cache

    # Stores the current Git commit hash into a .git-commit file within the backend deployment directory.
    # This helps in tracking which version of the code is currently deployed.
    - name: Store Git commit hash in backend deployment directory
      if: steps.check_backend_changes.outputs.changes == 'true'
      run: |
        git rev-parse HEAD > .git-commit
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S cp .git-commit /opt/thebarcodeapi/barcodeAPI/

    # Sets up essential initial directory structure for the backend application,
    # including directories for persisted data (Postgres, Redis) and backups.
    - name: Setup initial directories for backend data and operations
      run: |
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S mkdir -p /opt/thebarcodeapi/barcodeAPI
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S mkdir -p /opt/thebarcodeapi/${ENVIRONMENT}/releases/data/postgres
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S mkdir -p /opt/thebarcodeapi/${ENVIRONMENT}/releases/data/redis
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S mkdir -p /opt/thebarcodeapi/${ENVIRONMENT}/backups/
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S chown -R github-runner:github-runner /opt/thebarcodeapi/barcodeAPI

    - name: Setup Docker and Environment
      run: |
        # Add runner to docker group if not already added
        if ! groups | grep -q docker; then
          echo "${{ env.SUDO_PASSWORD }}" | sudo -S usermod -aG docker $USER
          # Reload groups without logging out
          exec sg docker newgrp docker
        fi

        # Create /tmp/env_vars file with environment variables needed by the backend deployment script.
        # This file is sourced by scripts/deploy-backend-docker.sh.
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S bash -c "cat > /tmp/env_vars << EOF
ENVIRONMENT=\${{ env.ENVIRONMENT }}
DB_PASSWORD=\${{ env.DB_PASSWORD }}
POSTGRES_PASSWORD=\${{ env.POSTGRES_PASSWORD }}
API_SECRET_KEY=\${{ env.API_SECRET_KEY }}
API_MASTER_KEY=\${{ env.API_MASTER_KEY }}
API_VERSION=\${{ vars.API_VERSION }}
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REDIS_URL=redis://redis:6379/1
SYNC_DATABASE_URL=postgresql+asyncpg://barcodeboachiefamily:\${{ env.DB_PASSWORD }}@db/barcode_api
LOG_DIRECTORY=logs
ROOT_PATH=/api/v1
SECRET_KEY=\${{ env.API_SECRET_KEY }}
MASTER_API_KEY=\${{ env.API_MASTER_KEY }}
DATABASE_URL=postgresql+asyncpg://barcodeboachiefamily:\${{ env.DB_PASSWORD }}@db/barcode_api
SERVER_URL=https://\${{ env.DOMAIN_NAME }}
EOF"

        # Determines the correct Docker Compose command (docker-compose or docker compose)
        # and saves it to /tmp/docker_vars for use in subsequent scripts.
        if command -v docker-compose &> /dev/null; then
            echo "${{ env.SUDO_PASSWORD }}" | sudo -S bash -c 'echo "DOCKER_COMPOSE=docker-compose" > /tmp/docker_vars'
        elif command -v docker &> /dev/null && docker compose version &> /dev/null; then
            echo "${{ env.SUDO_PASSWORD }}" | sudo -S bash -c 'echo "DOCKER_COMPOSE=docker compose" > /tmp/docker_vars'
        else
            echo "Neither docker-compose nor docker compose found!"
            exit 1
        fi

        # Debug output
        echo "Environment file contents:"
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S cat /tmp/env_vars
        echo "Docker compose file contents:"
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S cat /tmp/docker_vars

        # Verify Docker access
        docker ps # Verifies Docker daemon is accessible.

    # Executes the main backend deployment script.
    # This script is responsible for managing Docker Compose (down, up, build), handling data persistence,
    # database backups, and health checks for the backend services.
    - name: Deploy backend services via Docker Compose and perform health checks
      run: bash ./scripts/deploy-backend-docker.sh
      env:
        SUDO_PASSWORD: ${{ env.SUDO_PASSWORD }}
        ENVIRONMENT: ${{ env.ENVIRONMENT }} # Passed directly, though script also sources from /tmp/env_vars.
        DB_PASSWORD: ${{ env.DB_PASSWORD }}
        POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
        API_SECRET_KEY: ${{ env.API_SECRET_KEY }}
        API_MASTER_KEY: ${{ env.API_MASTER_KEY }}
        API_VERSION: ${{ vars.API_VERSION }}
        CHANGES: ${{ steps.check_backend_changes.outputs.changes }}

    - name: Verify deployment
      run: |
        # Check container status
        docker ps | grep -E "barcodeapi_(api|db|redis)"

        # Check API health
        curl -f http://localhost:8000/health || {
            echo "API health check failed."
            docker logs barcodeapi_api
            exit 1
        }

    # Executes a script to run database migrations using Alembic within the API container.
    - name: Run database migrations for backend
      run: bash ./scripts/run-migrations.sh
      env:
        SUDO_PASSWORD: ${{ env.SUDO_PASSWORD }} # Script uses sudo for `docker compose exec`.

    # Verifies the overall backend deployment by checking Docker container statuses,
    # recent logs, and performing a health check against the API endpoint.
    # It also handles cleanup of the temporary .env file used during verification.
    - name: Verify backend deployment status and API health
      run: |
        cd /opt/thebarcodeapi/barcodeAPI # Script expects to be in this directory for docker-compose commands.

        # Determine docker compose command
        if command -v docker-compose &> /dev/null; then
          COMPOSE_CMD="docker-compose"
        else
          COMPOSE_CMD="docker compose"
        fi

        # Set proper permissions
        # echo "${{ env.SUDO_PASSWORD }}" | sudo -S chown github-runner:github-runner /opt/thebarcodeapi/barcodeAPI/.env
        # echo "${{ env.SUDO_PASSWORD }}" | sudo -S chmod 644 /opt/thebarcodeapi/barcodeAPI/.env

        echo "Verifying backend deployment..."

        echo "Checking Docker containers status:"
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S $COMPOSE_CMD ps

        echo "Checking container logs (last 10 lines):"
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S $COMPOSE_CMD logs --tail=10

        echo "Testing backend health:"
        MAX_RETRIES=3
        RETRY_COUNT=0
        until curl -f http://localhost:8000/health || [ $RETRY_COUNT -eq $MAX_RETRIES ]; do
          echo "Backend health check failed, retrying in 5 seconds..."
          sleep 5
          RETRY_COUNT=$((RETRY_COUNT + 1))
        done

        if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
          echo "Backend health check failed after $MAX_RETRIES attempts"
          echo "${{ env.SUDO_PASSWORD }}" | sudo -S $COMPOSE_CMD logs api
          echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -f /opt/thebarcodeapi/barcodeAPI/.env
          exit 1
        fi

        echo "Backend verification completed successfully"

        # Cleanup of the .env file specific to this verification step; the main .env for the container is managed by create-backend-env-file.sh.
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -f /opt/thebarcodeapi/barcodeAPI/.env

    # Performs a Docker system prune to remove unused Docker data (images, containers, volumes, networks)
    # to free up disk space. Runs even if previous steps in the job fail.
    - name: Clean up unused Docker resources on runner
      if: always()
      run: |
        cd /opt/thebarcodeapi/barcodeAPI # Context for docker-compose related prune if applicable, though `docker system prune` is global.
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S docker system prune -f --volumes

    # Final cleanup of the backend .env file created by 'Create .env file for backend services' step.
    # This ensures that sensitive data in this specific .env file (if different from the one inside Docker) is removed after deployment.
    - name: Final cleanup of backend .env file from host
      if: always()
      run: |
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -f /opt/thebarcodeapi/barcodeAPI/.env

    # Performs a final status check on all critical services (API, Redis, Database)
    # to ensure they are running and responsive after the deployment process.
    - name: Final status check of all backend services
      run: |
        echo "Performing final status check..."

        # Check app containers
        if ! docker ps | grep -q "barcodeapi_api"; then
          echo "API container is not running!"
          exit 1
        fi

        # Check Redis
        if ! docker ps | grep -q "barcodeapi_redis"; then
          echo "Redis container is not running!"
          exit 1
        fi

        # Check Database
        if ! docker ps | grep -q "barcodeapi_db"; then
          echo "Database container is not running!"
          exit 1
        fi

        # Check API health
        if ! curl -s -f http://localhost:8000/health > /dev/null; then
          echo "API health check failed!"
          exit 1
        fi

        echo "All services are running correctly!"

  final-verification: # This job runs after both frontend and backend deployments.
    runs-on: self-hosted
    needs: [frontend-deployment, backend-deployment] # Ensures it runs only if both dependencies succeed (unless `if: always()` is used on this job).
    steps:

    # Cleans up build artifacts (like .next, build directories, package files) from the runner's workspace.
    # Also runs a Docker system prune, which might be redundant if the backend job already did it.
    - name: Clean up build artifacts from runner workspace
      if: always() # Run this step regardless of the success or failure of previous jobs/steps.
      run: |
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -rf .next
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -rf build
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -f package.json package-lock.json
        # Clean docker unused resources - this is a repeat from the backend job, consider if necessary here.
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S docker system prune -f --volumes

    # If any of the preceding jobs (frontend-deployment, backend-deployment) or steps in this job failed,
    # this step collects diagnostic information from PM2, Docker, and Nginx, and cleans up temporary files.
    - name: Notify and collect diagnostics on deployment failure
      if: failure() # Run this step only if a failure occurred in this job or its dependencies.
      run: |
        echo "============================================"
        echo "Deployment failed! Collecting diagnostic information..."
        echo "============================================"

        echo "PM2 Status:"
        pm2 list || true

        echo "Docker Container Status:"
        docker ps -a || true

        echo "Recent Docker Logs:"
        docker-compose -f /opt/thebarcodeapi/barcodeAPI/docker-compose.yml logs --tail=50 || true

        echo "Nginx Status:"
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S systemctl status nginx || true

        echo "Cleaning up temporary files..."
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -f /tmp/env_vars
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -f /tmp/docker_vars
        echo "${{ env.SUDO_PASSWORD }}" | sudo -S rm -f /opt/thebarcodeapi/barcodeAPI/.env

        echo "============================================"
        # exit 1